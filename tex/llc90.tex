\section{Application to the Global Ocean}
\label{sec:llc90}

Here we show results from a numerical implementation of the correlation model
described in \cref{sec:matern_operator}.
For this application we use the ``Lat-Lon-Cap'' (LLC) grid used by the ECCOv4
state estimate \cite[][see Sec. 2 for a complete description of the grid]{forgetECCOv4}.
The overall goal with these numerical experiments is to show that even in this
relatively complicated global grid, the
correlation model generally follows the expected Mat\'ern correlation structure
(\cref{ssec:llc90_correlations}), while maintaining
anisotropy and nonstationarity that is relevant to the physical system
(\cref{ssec:llc90_correlation_maps}).
Additionally, we show how Neumann boundary conditions to the differential
operator affect the solution in \cref{ssec:llc90_boundary_effects}.
We finish
by showing that the model can be applied efficiently with a relatively imprecise
solver tolerance (\cref{ssec:tolerance}) and that it is relatively cheap even
when the number of applications, $M$, is greater than one
(\cref{ssec:iters_and_apps}).

For all experiments, we compute statistical quantities from 1,000 samples
(see \cref{sec:discretization_matern} and specifically
\cref{eq:corr_operator_fv,eq:sampling} for sampling details).
We use a block-Successive Over Relaxation (SOR) method (\cref{sec:block_sor}) to find numerical
solutions to the elliptic SPDE, using a tolerance of $10^{-3}$ for all results
except where specified in \cref{ssec:tolerance}.
Additionally, we use the following normalizing length scales
$L_x(i,j) = \Delta x_g(i,j)$, $L_y(i,j) = \Delta y_g(i,j)$,
and $L_z(k) = \Delta r_f(k)$ (\cref{fig:mitgcm_grid}) where we have switched
from the spatial coordinate $\x\in\domain$ to the computational grid indices $i$, $j$, $k$.
All experiments are performed with a 3D field, which could represent an ocean
state property like temperature or salinity.

\subsection{Correspondence with theoretical correlation structure}
\label{ssec:llc90_correlations}

We first show that the sample correlation structure computed on the LLC
grid corresponds with the analytical Mat\'ern-type correlation function
(\cref{eq:matern_corr_isostat}).
For this comparison we compute the correlation field in the transformed space
$\defdomain$, where it can be considered isotropic and stationary.
Because we use the grid spacing to define this mapping, the correlation
distances are computed simply by counting the number of neighboring grid cells in each
direction from the point in consideration.
%We refer to this distance as $\delta\hat{x}$, $\delta\hat{y}$, and
%$\delta\hat{z}$ for the longitudinal, meridional, and vertical dimensions
%respectively.

\cref{fig:llc90_correlations} shows the comparison between the theoretically
expected correlation structure (black) and the numerically computed sample
correlation structure for
$\rangeh = \{5, 10, 15, 20\}$ (color) using $M =\{1,2,4,8\}$ (panels).
Recall that as $M$ increases, the correlation structure approaches a Gaussian
shape, such that there is little visible difference between e.g.\ $M=4$ and
$M=8$.
The correlation is computed in the direction of longitude, indicated by
$\delta i$.
The shading indicates the spread between the first and ninth deciles of the
sample correlation, computed at all depth levels and latitudes from
70$^\circ$S to 37$^\circ$N at 127.5$^\circ$W - a subset chosen simply to ease the
calculation.
Similar plots showing correlation in the meridional and vertical directions are
shown in the Supplemental Material.

Generally speaking, the colored curves match the analytical expression well, and
each colored curve intersects the horizontal gray line, indicating a correlation
value of 0.14, where $\rangeh = \delta i$.
We note that the largest spread in the computed correlation structure occurs
when $M=1$, especially for larger values of $\rangeh$.
Considering an analogy to Laplacian versus biharmonic damping in ocean models
\citep[e.g.][]{holland_role_1978,griffies_biharmonic_2000}, we suggest that
there is more spread when $M=1$ because the operator $\maternop^{-1}$
contains a only a Laplacian term.
Compared to the cases when $M>1$, which contain biharmonic and higher order
Laplacian terms in $\maternop^{-M}$, the Laplacian case is less
scale-selective.
That is, the operator does not cutoff higher frequency variability sharply,
allowing noise to pollute the sample statistics \citep[see][Section 2 for a quantitative
description of this cutoff in frequency space]{griffies_biharmonic_2000}.
We note, however, that the spread still allows for a reasonable interpretation
that the operator $\maternop^{-1}$ captures the behavior of the analytical Mat\'ern correlation
function.

\begin{figure}
    \centering
    \begin{overpic}[width=\textwidth]{../figures/matern_llc90_correlation_theory_vs_m_ix.pdf}
        \put(6,35){(a)}
        \put(30,35){(b)}
        \put(53,35){(c)}
        \put(76,35){(d)}
    \end{overpic}
    \caption{Correlation structure computed from the theoretical Mat\'ern
        correlation function (black; \cref{eq:matern_corr_isostat}) and from
        1,000 samples using a subset of the ``Lat-Lon-Cap'' grid within the
        Pacific Ocean (shaded coloring).
        The sample correlation is computed in the zonal direction, $\delta i$,
        indicating number of neighboring grid cells from
        127.5$^\circ$W.
        The shading indicates the spread between the first and ninth deciles,
        based on sample correlations at all depth levels and latitudes from
        70$^\circ$S and 37$^\circ$N.
        Similar plots showing correlation as a function of meridional and
        vertical distance are provided in the Supplemental Material.
        Recall that as $M\rightarrow\infty$, the Mat\'ern correlation function
        approaches a Gaussian (cf. \cref{fig:correlation_comparison}).
    }
    \label{fig:llc90_correlations}
\end{figure}

\subsection{Sample correlation maps}
\label{ssec:llc90_correlation_maps}

Maps of the sample correlation field on the LLC grid are shown in
\cref{fig:llc90_correlation_maps}, at
(0.2$^\circ$N, 127.5$^\circ$W, 722~m depth) and
(10.5$^\circ$N, 87.5$^\circ$W, 5~m depth) in panels (a \& d) and (b \& e), respectively.
These two locations are chosen to highlight local anisotropy in the
latitude-longitude plane and nonstationarity in the vertical axis.
For these calculations we use a perhaps unrealistically large correlation length scale
defined by $\rangeh=20$ for illustrative purposes.

Comparing panels (a) and (b) of \cref{fig:llc90_correlation_maps}, we see that
near the equator, the correlation structure is stretched zonally, while poleward
of $\sim 10-15^\circ$ the structure is closer to being isotropic.
Elongated zonal correlation length scales at the equator are consistent with
observations \citep{meyers_space_1991}, so we
consider this anisotropic behavior to be desirable.
In our case, we achieve this anisotropy via local refinements in the
meridional grid scale near the equator, which are specifically designed to
capture tropical zonal currents \citep{forgetECCOv4}.
Specifically, \cref{fig:llc90_correlation_maps}(c) shows how the meridional grid
spacing ($\Delta y$) refines near the equator, while the longitudinal grid
spacing ($\Delta x$) slightly increases near the equator.
The result of this grid refinement is that near the equator, a range of
$\rangeh$ grid cells covers a shorter distance meridionally than it does at
e.g.\ $20^\circ$N.
Overall, this example highlights how details in the model grid can be harnessed
to achieve physically relevant correlation structures.
However, we note that if this correlation shape is desired but would not
immediately occur due to a different model grid definition, then the normalizing length
scales could easily be modified with a weighting function to achieve the
desired structure.

\begin{figure}
    \centering
    \begin{overpic}[width=\textwidth]{../figures/huge_correlation_map_02apps.jpg}
        \put(4.25,46.5){(a)}
        \put(37,46.5){(b)}
        \put(72,47.25){(c)}
        \put(4.25,26){(d)}
        \put(37,26){(e)}
        %\put(72,23){(f)}
        \put(66.5,26){(f)}
        %\put(72,28){(f)}
    \end{overpic}
    \caption{Two sample correlation fields and a depiction of the computational
        grid.
        (a \& b) Sample correlation field in the latitude-longitude plane at
        (0.2$^\circ$N, 127.5$^\circ$W, 722~m depth) and
        (10.5$^\circ$N, 87.5$^\circ$W, 5~m depth), respectively.
        (c \& d) The same sample correlation fields as above, shown in the
        depth-longitude plane.
        (e \& f) The local horizontal and vertical grid spacing, respectively.
        The correlation fields are computed with $\rangeh = 20$ and $M=2$.
    }
    \label{fig:llc90_correlation_maps}
\end{figure}

Panels (d) and (e) of \cref{fig:llc90_correlation_maps}
illustrate nonstationary correlation structures obtained along the vertical axis.
As discussed in \cref{ssec:nonstationarity}, it would be reasonable to expect
shorter correlation lengths near the ocean surface due to localized processes
there, and relatively longer correlation length scales in the interior
ocean.
This general behavior is shown in panel (e), where correlation $>0.1$ is
confined to the upper hundred meters of the ocean, while in panel (d),
correlation $>0.1$ spans the full depth of the ocean.
Once again, the correlation structures shown here correspond directly to the
vertical grid spacing, which is shown in \cref{fig:llc90_correlation_maps}(f).


\subsection{Pointwise sample standard deviation}
\label{ssec:llc90_boundary_effects}


The pointwise, sample standard deviation is shown in \cref{fig:std_ratio}, where
it is represented as a ratio with respect to the ``expected'' value from
\cref{eq:matern_variance} for an isotropic, stationary Mat\'ern field.
Throughout most of the domain, the sample standard deviation is approximately
equal to the theoretical value.
Near continental boundaries, however, the standard deviation is inflated, especially
for large values of $\rangeh$ and in regions of tightly confined topographic
boundaries such as in the Caribbean Sea.
This deviation near the boundaries is expected for correlation models based on
the solution of differential equations
\citep[e.g.][]{weaver_correlation_2001,RSSB:RSSB777}, as a result of the zero
flux, Neumann boundary conditions used to find the solution.
Thus, the theoretical value cannot be used directly and it is necessary to
calculate or estimate the true variance of the operator in order to formulate
the normalization matrix $\normalizer$.
Throughout this work, we have used the estimated standard deviation shown in
\cref{fig:std_ratio} to fill $\normalizer$, based on 1,000 random samples
(as suggested in \citet{weaver_correlation_2001}).
Given that the numerical computed correlation structure compares well to the
theoretical value (\cref{ssec:llc90_correlations}), this normalization method
appears to be reliable.
We also note this method is convenient because it is embarrassingly parallel,
and scales well to arbitrarily high dimensional fields.
However, for cases when the correlation operator is to be updated repeatedly,
e.g.\ in cycled DA, other normalization methods could be explored for use with
this operator as in \citet{weaver_evaluation_2021}.

\begin{figure}
    \centering
    \begin{overpic}[width=\textwidth]{../figures/std_ratio_02apps.jpg}
        \put(3.75,43.5){(a)}
        \put(28.5,43.5){(b)}
        \put(53.25,43.5){(c)}
        \put(77.75,43.5){(d)}
        \put(3.75,27){(e)}
        \put(28.5,27){(f)}
        \put(53.25,27){(g)}
        \put(77.75,27){(h)}
    \end{overpic}
    \caption{The ratio of the sample standard deviation to the value computed
        from \cref{eq:matern_variance} for an isotropic, stationary Mat\'ern
        field (indicated in the bottom row by $\hat{\sigma}$).
        Panels (a-d) show the ratio in the latitude-longitude plane at
        the surface for $\rangeh=\{5,10,15,20\}$, respectively. Panels (e-h)
        show the corresponding fields in the depth-longitude plane along 10.5$^\circ$N.
        The largest deviations from the theoretical value are near the boundaries, as
        expected.
        All fields use $M=2$.
    }
    \label{fig:std_ratio}
\end{figure}

\subsection{High efficiency with low precision}
\label{ssec:tolerance}

The numerical results shown in this section have employed the
iterative algorithm in \cref{sec:block_sor} to obtain approximate correlation
statistics.
As with any iterative algorithm, one must specify a
tolerance that can be used to determine when the algorithm has converged to an
approximate solution.
Within this framework, one can always set a tolerance based on the numerical
precision being used to be confident that the solver has converged.
However, in this section we show that this is likely to be
unnecessarily ambitious.

To be specific, \cref{fig:error_and_iters}(a) shows the relative error in the
approximation that correlation is equal to 0.14 when $\rangeh = \delta i$
for $\rangeh = \{5, 10, 15, 20\}$ (i.e.\ corresponding to the curves in
\cref{fig:llc90_correlations}).
The error in the approximation is shown for a range of solver tolerances,
where $10^{-15}$ is chosen as an approximate lower bound tolerance for double
precision.
For tolerances at $10^{-3}$ and smaller, the error coverges to roughly the same
value, indicating that the desired statistics of the correlation
model are obtained even with a relatively imprecise solve.
We note that \citet{carrier_background-error_2010} describe similar findings
with the implicit diffusion correlation model.

The motivation for using a high tolerance is indicated by
\cref{fig:error_and_iters}(b), which shows how the number of iterations required
to converge increases with the specified tolerance.
Solving to a tolerance of $10^{-15}$ requires a factor of 6-13
more iterations than are required with a tolerance of $10^{-3}$.
Of course, the specific computational savings obtained will depend on the
iterative method that is being used, but we provide this as a concrete example
to highlight that an imprecise solve is both valid and advantageous.

\begin{figure}
    \centering
    \begin{overpic}[width=\textwidth]{../figures/matern_llc90_error_and_iters_01apps.pdf}
        \put(6.5,24.5){(a)}
        \put(46.5,24.5){(b)}
    \end{overpic}
    \caption{(a) The relative error in the approximation that correlation equals
        0.14 when $\rangeh=\delta i$, as a function of the tolerance used
        for the iterative block-SOR method described in \cref{sec:block_sor}.
        Each curve is computed as the error between the theoretical (black)
        curve and the average of each shaded curve shown in \cref{fig:llc90_correlations}.
        (b) The number of iterations required for the block-SOR method to
        converge to the specified tolerance.
        Averages are computed from 1,000 samples using $M=1$.
    }
    \label{fig:error_and_iters}
\end{figure}

\subsection{Rapid convergence for $M>1$}
\label{ssec:iters_and_apps}

For applications where a Gaussian correlation structure is desired, the
correlation model presented here requires $M>1$ to approach the Gaussian
structure (\cref{fig:correlation_comparison}).
Moreover, it could also be desirable to use $\maternop^{-M}$ with $M>1$,
given that $M=1$ produces larger spread in the correlation structure
(\cref{fig:llc90_correlations}(a)), and because the correlation structure drops
off much more rapidly for neighboring points.
For these cases, it may be natural to assume that using this model with $M>1$
would be less efficient than when $M=1$ because it requires multiple
applications of an inverse elliptic operator.
However, here we show that this is not necessarily true and it can be
\textit{more} efficient to use $M>1$ than $M=1$.

\cref{fig:iters_and_apps}(a) shows the total number of iterations required to
find a solution to \cref{eq:matern_operator}, for a variety of combinations of
$\rangeh$ and $M$.
Here, ``total iterations'' refers to all block-SOR iterations
required by the algorithm in \cref{sec:block_sor}, summing over all applications
of $\maternop^{-M}$.
Evidently, using $M>1$ actually requires \textit{fewer} total iterations to converge to a
solution than when $M=1$.
The reason for this is as follows.
For any value of $\rangeh$, $\deltah$ increases linearly with $M$, which
increases the amplitude of the diagonal elements of the matrix representation of
$\maternop$.
In each case, the off-diagonal matrix elements, determined by the Laplacian
operator, remain fixed.
Thus, the matrix becomes more diagonally dominant:
the amplitude of the diagonal elements increases relative to the sum total of
off-diagonals.
The degree of diagonal dominance is an important property for
determining the convergence of our SOR-based elliptic solver, where a more
diagonally dominant matrix tends to converge faster \citep{golub_matrix_2013}.
Evidence of this behavior can be seen in \cref{fig:iters_and_apps}(b), which shows the
number of iterations required for each individual application of
$\maternop^{-1}$ to converge.
Here we see that each application gets cheaper as $M$, and therefore $\deltah$,
increases.
The improvement per iteration is evidently enough to reduce the total
iterations, shown in panel (a).
The exception to this behavior is when $\rangeh = 5$, where for $M\ge 4$
the total number of iterations overtakes the case of $M=1$ due to the repeated
solves.

We note that Jacobi, Gauss-Seidel, and SOR methods are rarely used for modern
applications.
For example, the MITgcm
\citep{marshall_finite-volume_1997,campin_mitgcmmitgcm_2021}
uses a conjugate gradient method for the pressure solve at each time
step.
However, given the performance benefits noted here and the simplicity of
implementing e.g.\ the SOR scheme, it could be used as an efficient
preconditioner in the event that e.g.\ a conjugate gradient scheme becomes
overly expensive for $M>1$.

\begin{figure}
    \centering
    \begin{overpic}[width=.4\textwidth]{../figures/iterations_vs_applications.pdf}
        \put(-6,95){(a)}
        \put(-6,48){(b)}
    \end{overpic}
    \caption{(a) Total number of iterations required to compute
        $\unis = \maternop^{-M}\mathbf{z}$, for a standard normally distributed
        vector $\mathbf{z}\in\ndspace$.
        ``Total iterations'' is represented as the average number of total
        iterations from 1,000 random samples.
        (b) The average number of iterations per application of
        $\maternop^{-M}$, as a function of $M$.
        For all $\rangeh$ and $M$ combinations, each application gets cheaper as
        $M$ increases.
        To compute the ``average iterations per application'', we take the
        average iteration per application of $\maternop^{-M}$, and compute the sample
        average of this quantity from 1,000 random samples.
    }
    \label{fig:iters_and_apps}
\end{figure}
